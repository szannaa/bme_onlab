{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_xml(xml_doc):\n",
    "    attr = xml_doc.attrib\n",
    "    for xml in xml_doc.iter('vehicle'):\n",
    "        _dict = attr.copy()\n",
    "        _dict.update(xml.attrib)\n",
    "        \n",
    "        yield _dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_per_liter = 624 / 1.27\n",
    "eta = 0.45\n",
    "m = 18000\n",
    "g = 9.81\n",
    "mg_to_liter = 0.0000011765\n",
    "liter_to_joule = 38000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_up(emission, delta_h):\n",
    "    emission = emission * mg_to_liter * liter_to_joule\n",
    "    emission = emission + (1/eta) * m * g * delta_h\n",
    "    emission = emission * (1/liter_to_joule)\n",
    "    emission = emission * price_per_liter\n",
    "    return emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_down(emission, delta_h):\n",
    "    emission = emission * mg_to_liter * liter_to_joule\n",
    "    emission = emission - (1/eta) * m * g * delta_h\n",
    "    emission = emission * (1/liter_to_joule)\n",
    "    emission = emission * price_per_liter\n",
    "    return emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_folder(path):\n",
    "    # Normalize the path to handle different separators and remove trailing separator\n",
    "    normalized_path = os.path.normpath(path)\n",
    "    # Split the path into components\n",
    "    folders = normalized_path.split(os.sep)\n",
    "    # Get the last folder\n",
    "    last_folder = folders[-1]\n",
    "    return last_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_elevation_up(group):\n",
    "    z_diff = pd.to_numeric(group['z']).diff()\n",
    "\n",
    "    # Filter out negative differences (upward movement)\n",
    "    up = z_diff.apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "    # Sum the positive differences to get the total upward movement\n",
    "    total_up = up.sum()\n",
    "    return total_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_elevation_down(group):\n",
    "    z_diff = pd.to_numeric(group['z']).diff()\n",
    "\n",
    "    # Filter out negative differences (upward movement)\n",
    "    down = z_diff.apply(lambda x: x if x < 0 else 0)\n",
    "\n",
    "    # Sum the positive differences to get the total upward movement\n",
    "    total_down = down.sum()\n",
    "    return total_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_xml_tripinfo(xml_doc):\n",
    "    attr = xml_doc.attrib\n",
    "    for xml in xml_doc.iter('tripinfo'):\n",
    "        _dict = attr.copy()\n",
    "        _dict.update(xml.attrib)\n",
    "        \n",
    "        yield _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_routeids_df(base_folder):\n",
    "    file_path = os.path.join(base_folder, \"trips.txt\")\n",
    "    return pd.read_csv(file_path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_route_id(trip_id, trip_ids):\n",
    "    trip_id = trip_id[:-2]\n",
    "    line = trip_ids.loc[trip_ids['trip_id'] == trip_id]\n",
    "    route_id = line.iloc[0]['route_id']\n",
    "\n",
    "    return route_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_xml_stops(xml_doc):\n",
    "    for route in xml_doc.iter('route'):\n",
    "        route_dict = route.attrib.copy()\n",
    "        stops = []\n",
    "        \n",
    "        # Iterate over each <stop> element within the current <route> element\n",
    "        for stop in route.findall('stop'):\n",
    "            stop_dict = stop.attrib.copy()\n",
    "            stops.append(stop_dict)\n",
    "        \n",
    "        # Include stops in the route dictionary\n",
    "        route_dict['stops'] = stops\n",
    "        \n",
    "        yield route_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seed, scale):\n",
    "    print(seed + \" \" + scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"C:\\\\Users\\\\Admin\\\\Sumo\\\\nap_gellert_e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(base_folder, \"emission.out.xml\")\n",
    "shutil.copyfile(file_path, \"output\\\\emission_\")\n",
    "emission_output = et.parse(file_path)\n",
    "\n",
    "transform = transform_xml(emission_output.getroot())\n",
    "emission_output_list = list(transform)\n",
    "\n",
    "emission_output_df = pd.DataFrame(emission_output_list)\n",
    "emission_output_df = emission_output_df.drop(emission_output_df.columns[0], axis=1)\n",
    "\n",
    "#emission_output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emission_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(base_folder, \"tripinfo.xml\")\n",
    "\n",
    "b_tripinfo_output = et.parse(file_path)\n",
    "\n",
    "transform = transform_xml_tripinfo(b_tripinfo_output.getroot())\n",
    "b_tripinfo_output_list = list(transform)\n",
    "\n",
    "b_tripinfo_output_pd = pd.DataFrame(b_tripinfo_output_list)\n",
    "b_tripinfo_output_pd = b_tripinfo_output_pd.drop(b_tripinfo_output_pd.columns[0], axis=1)\n",
    "#b_tripinfo_output_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(base_folder, \"gtfs_pt_vehicles.add.xml\")\n",
    "stops = et.parse(file_path)\n",
    "\n",
    "transform = transform_xml_stops(stops.getroot())\n",
    "stops_list = list(transform)\n",
    "\n",
    "stops_pd = pd.DataFrame(stops_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(base_folder, \"gtfs_pt_vehicles.add.xml\")\n",
    "vehicles = et.parse(file_path)\n",
    "\n",
    "transform = transform_xml(vehicles.getroot())\n",
    "vehicles_list = list(transform)\n",
    "\n",
    "vehicles_pd = pd.DataFrame(vehicles_list)\n",
    "vehicles_pd = vehicles_pd.drop(vehicles_pd.columns[0], axis=1)\n",
    "#vehicles_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_ids_df = get_routeids_df(base_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = emission_output_df.groupby('id')\n",
    "\n",
    "list_of_dfs = [group_data for _, group_data in grouped_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "for group_id, group_data in grouped_df:\n",
    "    avg_speed = group_data['speed'].astype(float).mean()\n",
    "\n",
    "    time_loss = b_tripinfo_output_pd.loc[b_tripinfo_output_pd['id'] == group_id, 'timeLoss'].values[0]\n",
    "    route_length = b_tripinfo_output_pd.loc[b_tripinfo_output_pd['id'] == group_id, 'routeLength'].values[0]\n",
    "    \n",
    "    route = vehicles_pd.loc[vehicles_pd['id'] == group_id, 'route'].values[0]\n",
    "    count_stops = stops_pd[stops_pd['id'] == route]['stops'].apply(len).sum()\n",
    "    \n",
    "    z_up = calc_elevation_up(group_data)\n",
    "    z_down = calc_elevation_down(group_data)\n",
    "    \n",
    "    d_height = z_up + z_down\n",
    "    \n",
    "    fuel_sum = group_data['fuel'].astype(float).sum()\n",
    "    \n",
    "    route_id = get_route_id(group_id, route_ids_df)\n",
    "    \n",
    "    if(d_height >= 0):\n",
    "        fuel_sum = get_price_up(group_data['fuel'].astype(float).sum(), d_height)\n",
    "    else:\n",
    "        fuel_sum = get_price_down(group_data['fuel'].astype(float).sum(), d_height)\n",
    "    \n",
    "    # Store the results in a dictionary\n",
    "    group_result = {\n",
    "        'routeid': route_id,\n",
    "        'id': group_id,\n",
    "        'avgSpeed': avg_speed,\n",
    "        'fuel': fuel_sum,\n",
    "        'timeloss': time_loss,\n",
    "        'routeLength': route_length,\n",
    "        'numOfStops': count_stops,\n",
    "        'up': z_up,\n",
    "        'down': z_down\n",
    "    }\n",
    "    \n",
    "    # Append the dictionary to the results list\n",
    "    results.append(group_result)\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "result_df = pd.DataFrame(results)\n",
    "#print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableEmission = pd.read_csv('emissionData.csv', delimiter=';')\n",
    "\n",
    "#tableEmission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locSetting = get_last_folder(base_folder)\n",
    "seedSetting = 'dd'\n",
    "trafficScaleSetting = 'wh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in result_df.iterrows():\n",
    "    row_data = {\n",
    "        'routeId': row['routeid'],\n",
    "        'loc': locSetting,\n",
    "        'tripId': row['id'],\n",
    "        'seed': seedSetting,\n",
    "        'avgSpeed': row['avgSpeed'],\n",
    "        'timeloss': row['timeloss'],\n",
    "        'route_length': row['routeLength'],\n",
    "        'elevation_up': row['up'],\n",
    "        'elevation_down': row['down'],\n",
    "        'trafficScale': trafficScaleSetting,\n",
    "        'numOfStops': row['numOfStops'],\n",
    "        'emission': row['fuel']\n",
    "    }\n",
    "    temp_df = pd.DataFrame([row_data])\n",
    "    #any empty or all-NA columns in tableEmission are excluded before concatenating the DataFrames\n",
    "    tableEmission = tableEmission.dropna(axis=1, how='all')\n",
    "\n",
    "    tableEmission = pd.concat([tableEmission, temp_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>routeId</th>\n",
       "      <th>loc</th>\n",
       "      <th>tripId</th>\n",
       "      <th>seed</th>\n",
       "      <th>avgSpeed</th>\n",
       "      <th>timeloss</th>\n",
       "      <th>route_length</th>\n",
       "      <th>elevation_up</th>\n",
       "      <th>elevation_down</th>\n",
       "      <th>trafficScale</th>\n",
       "      <th>numOfStops</th>\n",
       "      <th>emission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0330</td>\n",
       "      <td>nap_gellert_e</td>\n",
       "      <td>C622152254.0</td>\n",
       "      <td>dd</td>\n",
       "      <td>4.476667</td>\n",
       "      <td>107.76</td>\n",
       "      <td>1023.22</td>\n",
       "      <td>18.70</td>\n",
       "      <td>-10.67</td>\n",
       "      <td>wh</td>\n",
       "      <td>3</td>\n",
       "      <td>440.730048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0330</td>\n",
       "      <td>nap_gellert_e</td>\n",
       "      <td>C622155141.0</td>\n",
       "      <td>dd</td>\n",
       "      <td>4.791268</td>\n",
       "      <td>92.44</td>\n",
       "      <td>1023.22</td>\n",
       "      <td>18.62</td>\n",
       "      <td>-10.59</td>\n",
       "      <td>wh</td>\n",
       "      <td>3</td>\n",
       "      <td>412.522497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9722</td>\n",
       "      <td>nap_gellert_e</td>\n",
       "      <td>C6305325.0</td>\n",
       "      <td>dd</td>\n",
       "      <td>4.905053</td>\n",
       "      <td>196.64</td>\n",
       "      <td>1866.71</td>\n",
       "      <td>17.58</td>\n",
       "      <td>-19.50</td>\n",
       "      <td>wh</td>\n",
       "      <td>4</td>\n",
       "      <td>649.552646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2400</td>\n",
       "      <td>nap_gellert_e</td>\n",
       "      <td>C63598134.0</td>\n",
       "      <td>dd</td>\n",
       "      <td>4.487733</td>\n",
       "      <td>72.81</td>\n",
       "      <td>673.45</td>\n",
       "      <td>8.64</td>\n",
       "      <td>-10.76</td>\n",
       "      <td>wh</td>\n",
       "      <td>2</td>\n",
       "      <td>282.611518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2400</td>\n",
       "      <td>nap_gellert_e</td>\n",
       "      <td>C6359838.0</td>\n",
       "      <td>dd</td>\n",
       "      <td>4.182375</td>\n",
       "      <td>83.03</td>\n",
       "      <td>673.45</td>\n",
       "      <td>8.24</td>\n",
       "      <td>-10.86</td>\n",
       "      <td>wh</td>\n",
       "      <td>2</td>\n",
       "      <td>255.707142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0085</td>\n",
       "      <td>nap_gellert_e</td>\n",
       "      <td>C78245617.0</td>\n",
       "      <td>dd</td>\n",
       "      <td>3.938365</td>\n",
       "      <td>774.54</td>\n",
       "      <td>8120.62</td>\n",
       "      <td>172.93</td>\n",
       "      <td>-219.05</td>\n",
       "      <td>wh</td>\n",
       "      <td>19</td>\n",
       "      <td>2846.921169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0085</td>\n",
       "      <td>nap_gellert_e</td>\n",
       "      <td>C78245945.0</td>\n",
       "      <td>dd</td>\n",
       "      <td>1.783998</td>\n",
       "      <td>3821.47</td>\n",
       "      <td>8685.16</td>\n",
       "      <td>239.14</td>\n",
       "      <td>-193.10</td>\n",
       "      <td>wh</td>\n",
       "      <td>18</td>\n",
       "      <td>4363.691776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1335</td>\n",
       "      <td>nap_gellert_e</td>\n",
       "      <td>C78257148.0</td>\n",
       "      <td>dd</td>\n",
       "      <td>5.509126</td>\n",
       "      <td>191.62</td>\n",
       "      <td>3407.49</td>\n",
       "      <td>99.13</td>\n",
       "      <td>-101.76</td>\n",
       "      <td>wh</td>\n",
       "      <td>4</td>\n",
       "      <td>1000.195321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1335</td>\n",
       "      <td>nap_gellert_e</td>\n",
       "      <td>C782571889.0</td>\n",
       "      <td>dd</td>\n",
       "      <td>5.169886</td>\n",
       "      <td>194.53</td>\n",
       "      <td>2724.58</td>\n",
       "      <td>87.49</td>\n",
       "      <td>-84.08</td>\n",
       "      <td>wh</td>\n",
       "      <td>4</td>\n",
       "      <td>807.428287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1335</td>\n",
       "      <td>nap_gellert_e</td>\n",
       "      <td>C782574680.0</td>\n",
       "      <td>dd</td>\n",
       "      <td>5.310062</td>\n",
       "      <td>236.86</td>\n",
       "      <td>3407.49</td>\n",
       "      <td>98.33</td>\n",
       "      <td>-101.11</td>\n",
       "      <td>wh</td>\n",
       "      <td>4</td>\n",
       "      <td>1022.804220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   routeId            loc        tripId seed  avgSpeed timeloss route_length  \\\n",
       "0     0330  nap_gellert_e  C622152254.0   dd  4.476667   107.76      1023.22   \n",
       "1     0330  nap_gellert_e  C622155141.0   dd  4.791268    92.44      1023.22   \n",
       "2     9722  nap_gellert_e    C6305325.0   dd  4.905053   196.64      1866.71   \n",
       "3     2400  nap_gellert_e   C63598134.0   dd  4.487733    72.81       673.45   \n",
       "4     2400  nap_gellert_e    C6359838.0   dd  4.182375    83.03       673.45   \n",
       "..     ...            ...           ...  ...       ...      ...          ...   \n",
       "56    0085  nap_gellert_e   C78245617.0   dd  3.938365   774.54      8120.62   \n",
       "57    0085  nap_gellert_e   C78245945.0   dd  1.783998  3821.47      8685.16   \n",
       "58    1335  nap_gellert_e   C78257148.0   dd  5.509126   191.62      3407.49   \n",
       "59    1335  nap_gellert_e  C782571889.0   dd  5.169886   194.53      2724.58   \n",
       "60    1335  nap_gellert_e  C782574680.0   dd  5.310062   236.86      3407.49   \n",
       "\n",
       "    elevation_up  elevation_down trafficScale  numOfStops     emission  \n",
       "0          18.70          -10.67           wh           3   440.730048  \n",
       "1          18.62          -10.59           wh           3   412.522497  \n",
       "2          17.58          -19.50           wh           4   649.552646  \n",
       "3           8.64          -10.76           wh           2   282.611518  \n",
       "4           8.24          -10.86           wh           2   255.707142  \n",
       "..           ...             ...          ...         ...          ...  \n",
       "56        172.93         -219.05           wh          19  2846.921169  \n",
       "57        239.14         -193.10           wh          18  4363.691776  \n",
       "58         99.13         -101.76           wh           4  1000.195321  \n",
       "59         87.49          -84.08           wh           4   807.428287  \n",
       "60         98.33         -101.11           wh           4  1022.804220  \n",
       "\n",
       "[61 rows x 12 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableEmission.to_csv('batteryData.csv', index=False, sep=';')\n",
    "#tableEmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(seed = 0, scale = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
